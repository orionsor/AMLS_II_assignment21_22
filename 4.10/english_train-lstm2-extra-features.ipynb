{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "168a2ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\luche\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from collections import Counter \n",
    "import itertools\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from joblib import dump, load\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c3cb8",
   "metadata": {},
   "source": [
    "# data import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba16870e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>embedding</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>number of exclamations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>negative</td>\n",
       "      <td>dear  the newOoffice for Mac is great and all ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[118309.0, 372306.0, 229153.0, 166369.0, 22830...</td>\n",
       "      <td>[dear, newooffice, mac, great, lync, update, c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>how about you make a system that doesnt eat m...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[231458.0, 350362.0, 126852.0, 132701.0, 15409...</td>\n",
       "      <td>[make, system, doesnt, eat, friggin, disc, tim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>I may be ignorant on this issue but should we ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[237383.0, 186885.0, 193637.0, 94875.0, 277466...</td>\n",
       "      <td>[may, ignorant, issue, celebrate, parental, le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Thanks to  I just may be switching over to</td>\n",
       "      <td>-1</td>\n",
       "      <td>[357161.0, 237383.0, 349661.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[thanks, may, switch]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a windows Universal App Wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[231458.0, 157049.0, 388091.0, 372227.0, 57667...</td>\n",
       "      <td>[make, game, window, universal, app, xboxone, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>ok good to know Punting at MetLife in Decembe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[164328.0, 209645.0, 295361.0, 242311.0, 11868...</td>\n",
       "      <td>[good, know, punt, metlife, december, task, ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[141948.0, 333081.0, 59937.0, 242311.0, 55915....</td>\n",
       "      <td>[everyone, sit, around, metlife, annoying, did...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[161068.0, 261597.0, 144744.0, 390139.0, 38289...</td>\n",
       "      <td>[giants, niner, fan, would, wan, sunday, night...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
       "      <td>1</td>\n",
       "      <td>[57178.0, 383068.0, 359356.0, 361707.0, 105227...</td>\n",
       "      <td>[anybody, want, ticket, tomorrow, colombia, pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mendez told me hed drive me to MetLife on Sund...</td>\n",
       "      <td>0</td>\n",
       "      <td>[240866.0, 355345.0, 175719.0, 129440.0, 24231...</td>\n",
       "      <td>[mendez, tell, hed, drive, metlife, sunday, re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5868 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "0     628949369883000832  negative   \n",
       "1     628976607420645377  negative   \n",
       "2     629023169169518592  negative   \n",
       "3     629179223232479232  negative   \n",
       "4     629186282179153920   neutral   \n",
       "...                  ...       ...   \n",
       "5863  639855845958885376  positive   \n",
       "5864  639979760735662080   neutral   \n",
       "5865  640196838260363269   neutral   \n",
       "5866  640975710354567168  positive   \n",
       "5867  641034340068143104   neutral   \n",
       "\n",
       "                                                  tweet  label  \\\n",
       "0     dear  the newOoffice for Mac is great and all ...     -1   \n",
       "1      how about you make a system that doesnt eat m...     -1   \n",
       "2     I may be ignorant on this issue but should we ...     -1   \n",
       "3          Thanks to  I just may be switching over to       -1   \n",
       "4     If I make a game as a windows Universal App Wi...      0   \n",
       "...                                                 ...    ...   \n",
       "5863   ok good to know Punting at MetLife in Decembe...      1   \n",
       "5864  everyone who sat around me at metlife was so a...      0   \n",
       "5865  what giants or niners fans would wanna go to t...      0   \n",
       "5866  Anybody want a ticket for tomorrow Colombia vs...      1   \n",
       "5867  Mendez told me hed drive me to MetLife on Sund...      0   \n",
       "\n",
       "                                              embedding  \\\n",
       "0     [118309.0, 372306.0, 229153.0, 166369.0, 22830...   \n",
       "1     [231458.0, 350362.0, 126852.0, 132701.0, 15409...   \n",
       "2     [237383.0, 186885.0, 193637.0, 94875.0, 277466...   \n",
       "3     [357161.0, 237383.0, 349661.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [231458.0, 157049.0, 388091.0, 372227.0, 57667...   \n",
       "...                                                 ...   \n",
       "5863  [164328.0, 209645.0, 295361.0, 242311.0, 11868...   \n",
       "5864  [141948.0, 333081.0, 59937.0, 242311.0, 55915....   \n",
       "5865  [161068.0, 261597.0, 144744.0, 390139.0, 38289...   \n",
       "5866  [57178.0, 383068.0, 359356.0, 361707.0, 105227...   \n",
       "5867  [240866.0, 355345.0, 175719.0, 129440.0, 24231...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "0     [dear, newooffice, mac, great, lync, update, c...   \n",
       "1     [make, system, doesnt, eat, friggin, disc, tim...   \n",
       "2     [may, ignorant, issue, celebrate, parental, le...   \n",
       "3                                 [thanks, may, switch]   \n",
       "4     [make, game, window, universal, app, xboxone, ...   \n",
       "...                                                 ...   \n",
       "5863  [good, know, punt, metlife, december, task, ho...   \n",
       "5864  [everyone, sit, around, metlife, annoying, did...   \n",
       "5865  [giants, niner, fan, would, wan, sunday, night...   \n",
       "5866  [anybody, want, ticket, tomorrow, colombia, pe...   \n",
       "5867  [mendez, tell, hed, drive, metlife, sunday, re...   \n",
       "\n",
       "      number of exclamations  \n",
       "0                          0  \n",
       "1                          1  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "...                      ...  \n",
       "5863                       0  \n",
       "5864                       0  \n",
       "5865                       0  \n",
       "5866                       0  \n",
       "5867                       0  \n",
       "\n",
       "[5868 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('./data_exclamation.pkl')\n",
    "#dataTest = pd.read_table('../input/semevalll/SemEval2017-test.txt', usecols=[1,2], encoding='utf-8', names=['sentiment', 'tweet'])                   \n",
    "#combine = [dataTrain,dataTest]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8994adb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 3017, 0: 2001, -1: 850})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ca3ad46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5868 entries, 0 to 5867\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   id                      5868 non-null   int64 \n",
      " 1   sentiment               5868 non-null   object\n",
      " 2   tweet                   5868 non-null   object\n",
      " 3   label                   5868 non-null   int64 \n",
      " 4   embedding               5868 non-null   object\n",
      " 5   tokenized               5868 non-null   object\n",
      " 6   number of exclamations  5868 non-null   int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 366.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dbeba73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617906fe",
   "metadata": {},
   "source": [
    "# add label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b3fdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORY_INDEX = {\n",
    "    \"negative\": -1,\n",
    "    \"neutral\": 0,\n",
    "    \"positive\": 1\n",
    "}\n",
    "\n",
    "\"\"\"import data \"\"\"\n",
    "raw_label = df['sentiment'].values.tolist()\n",
    "rawlabel = []\n",
    "for i in range(len(raw_label)):\n",
    "    rawlabel.append(CATEGORY_INDEX[raw_label[i]])\n",
    "rawlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a800c715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>negative</td>\n",
       "      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Microsoft how about you make a system that do...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>I may be ignorant on this issue but... should ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Thanks to @microsoft, I just may be switching ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a #windows10 Universal App...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>@Racalto_SK ok good to know. Punting at MetLif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mendez told me he'd drive me to MetLife on Sun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5868 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "0     628949369883000832  negative   \n",
       "1     628976607420645377  negative   \n",
       "2     629023169169518592  negative   \n",
       "3     629179223232479232  negative   \n",
       "4     629186282179153920   neutral   \n",
       "...                  ...       ...   \n",
       "5863  639855845958885376  positive   \n",
       "5864  639979760735662080   neutral   \n",
       "5865  640196838260363269   neutral   \n",
       "5866  640975710354567168  positive   \n",
       "5867  641034340068143104   neutral   \n",
       "\n",
       "                                                  tweet  label  \n",
       "0     dear @Microsoft the newOoffice for Mac is grea...     -1  \n",
       "1     @Microsoft how about you make a system that do...     -1  \n",
       "2     I may be ignorant on this issue but... should ...     -1  \n",
       "3     Thanks to @microsoft, I just may be switching ...     -1  \n",
       "4     If I make a game as a #windows10 Universal App...      0  \n",
       "...                                                 ...    ...  \n",
       "5863  @Racalto_SK ok good to know. Punting at MetLif...      1  \n",
       "5864  everyone who sat around me at metlife was so a...      0  \n",
       "5865  what giants or niners fans would wanna go to t...      0  \n",
       "5866  Anybody want a ticket for tomorrow Colombia vs...      1  \n",
       "5867  Mendez told me he'd drive me to MetLife on Sun...      0  \n",
       "\n",
       "[5868 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = rawlabel\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381a0843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>negative</td>\n",
       "      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Microsoft how about you make a system that do...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>I may be ignorant on this issue but... should ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Thanks to @microsoft, I just may be switching ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a #windows10 Universal App...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>@Racalto_SK ok good to know. Punting at MetLif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mendez told me he'd drive me to MetLife on Sun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5868 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "0     628949369883000832  negative   \n",
       "1     628976607420645377  negative   \n",
       "2     629023169169518592  negative   \n",
       "3     629179223232479232  negative   \n",
       "4     629186282179153920   neutral   \n",
       "...                  ...       ...   \n",
       "5863  639855845958885376  positive   \n",
       "5864  639979760735662080   neutral   \n",
       "5865  640196838260363269   neutral   \n",
       "5866  640975710354567168  positive   \n",
       "5867  641034340068143104   neutral   \n",
       "\n",
       "                                                  tweet  label  \n",
       "0     dear @Microsoft the newOoffice for Mac is grea...     -1  \n",
       "1     @Microsoft how about you make a system that do...     -1  \n",
       "2     I may be ignorant on this issue but... should ...     -1  \n",
       "3     Thanks to @microsoft, I just may be switching ...     -1  \n",
       "4     If I make a game as a #windows10 Universal App...      0  \n",
       "...                                                 ...    ...  \n",
       "5863  @Racalto_SK ok good to know. Punting at MetLif...      1  \n",
       "5864  everyone who sat around me at metlife was so a...      0  \n",
       "5865  what giants or niners fans would wanna go to t...      0  \n",
       "5866  Anybody want a ticket for tomorrow Colombia vs...      1  \n",
       "5867  Mendez told me he'd drive me to MetLife on Sun...      0  \n",
       "\n",
       "[5868 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_back = df.copy()\n",
    "df_back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d575a7",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1937e0c",
   "metadata": {},
   "source": [
    "## 1 data cleansing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610b62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0902c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_base(tweets, clean_object):\n",
    "        #tweets.loc[:, \"tweet\"].replace(clean_object, \"\", inplace=True)\n",
    "        tweets = re.sub(clean_object, ' ', tweets)\n",
    "        return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a74b97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(tweets):\n",
    "        return clean_base(tweets, re.compile(r\"http.?://[^\\s]+[\\s]?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dfbdee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_usernames(tweets):\n",
    "        return clean_base(tweets, re.compile(r\"@[^\\s]+[\\s]?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "090412aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtags(tweets):  # it unrolls the hashtags to normal words\n",
    "        for hashtag in map(lambda x: re.compile(re.escape(x)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
    "                                                                     \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
    "                                                                     \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                                     \"!\", \"?\", \".\", \"'\",\n",
    "                                                                     \"--\", \"---\", \"#\"]):\n",
    "            tweets = re.sub(hashtag, ' ', tweets)\n",
    "        return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea79e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(tweets):\n",
    "        return clean_base(tweets, re.compile(r\"\\s?[0-9]+\\.?[0-9]*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe15fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6010822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbbf0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3d63f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9de7fdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>negative</td>\n",
       "      <td>dear  the newOoffice for Mac is great and all ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>how about you make a system that doesnt eat m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>I may be ignorant on this issue but should we ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Thanks to  I just may be switching over to</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a windows Universal App Wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>ok good to know Punting at MetLife in Decembe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mendez told me hed drive me to MetLife on Sund...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5868 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "0     628949369883000832  negative   \n",
       "1     628976607420645377  negative   \n",
       "2     629023169169518592  negative   \n",
       "3     629179223232479232  negative   \n",
       "4     629186282179153920   neutral   \n",
       "...                  ...       ...   \n",
       "5863  639855845958885376  positive   \n",
       "5864  639979760735662080   neutral   \n",
       "5865  640196838260363269   neutral   \n",
       "5866  640975710354567168  positive   \n",
       "5867  641034340068143104   neutral   \n",
       "\n",
       "                                                  tweet  label  \n",
       "0     dear  the newOoffice for Mac is great and all ...     -1  \n",
       "1      how about you make a system that doesnt eat m...     -1  \n",
       "2     I may be ignorant on this issue but should we ...     -1  \n",
       "3          Thanks to  I just may be switching over to       -1  \n",
       "4     If I make a game as a windows Universal App Wi...      0  \n",
       "...                                                 ...    ...  \n",
       "5863   ok good to know Punting at MetLife in Decembe...      1  \n",
       "5864  everyone who sat around me at metlife was so a...      0  \n",
       "5865  what giants or niners fans would wanna go to t...      0  \n",
       "5866  Anybody want a ticket for tomorrow Colombia vs...      1  \n",
       "5867  Mendez told me hed drive me to MetLife on Sund...      0  \n",
       "\n",
       "[5868 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def processDocument(doc, stemmer): \n",
    "\n",
    "    #Replace @username with empty string\n",
    "    doc = remove_usernames(doc)\n",
    "    #Replace url with empty string\n",
    "    doc = remove_urls(doc)\n",
    "\n",
    "    \n",
    "    #doc = re.sub(r'@[^\\s]+', ' ', doc)\n",
    "    #doc = re.sub(r'_', ' ', doc)\n",
    "    \n",
    "    \n",
    "    doc = re.sub(r'\\n', ' ', doc)\n",
    "    doc = re.sub(r'\\d', '', doc)\n",
    "    #Convert www.* or https?://* to \" \"\n",
    "    doc = re.sub('(www\\.[^\\s])',' ',doc)\n",
    "    #Replace #word with word\n",
    "    doc = re.sub(r'#([^\\s]+)', r'\\1', doc)\n",
    "    \n",
    "    # remove punctuations\n",
    "    doc= remove_punctuations(doc)\n",
    "    # normalize the tweet\n",
    "    #doc= normalize_arabic(doc)\n",
    "    \n",
    "    #Replace numbers with empty string\n",
    "    doc = remove_numbers(doc)\n",
    "    #Replace @username with empty string\n",
    "    doc = remove_hashtags(doc)\n",
    "    # remove repeated letters\n",
    "    #doc=remove_repeating_char(doc)\n",
    "    \n",
    "    #stemming\n",
    "    doc = stemmer.stem(doc)\n",
    "   \n",
    "    return doc\n",
    "\n",
    "\n",
    "\n",
    "stemmer = ISRIStemmer()\n",
    "df[\"tweet\"] = df['tweet'].apply(lambda x: processDocument(x, stemmer))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "500939eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deddc7b5",
   "metadata": {},
   "source": [
    "# tokenization and stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbabd279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\luche\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ca7e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\luche\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bbe90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################trail 1#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb003971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['dear',\n",
       "   'the',\n",
       "   'newOoffice',\n",
       "   'for',\n",
       "   'Mac',\n",
       "   'is',\n",
       "   'great',\n",
       "   'and',\n",
       "   'all',\n",
       "   'but',\n",
       "   'no',\n",
       "   'Lync',\n",
       "   'update',\n",
       "   'Cmon'],\n",
       "  -1),\n",
       " (['how',\n",
       "   'about',\n",
       "   'you',\n",
       "   'make',\n",
       "   'a',\n",
       "   'system',\n",
       "   'that',\n",
       "   'doesnt',\n",
       "   'eat',\n",
       "   'my',\n",
       "   'friggin',\n",
       "   'discs',\n",
       "   'This',\n",
       "   'is',\n",
       "   'the',\n",
       "   'nd',\n",
       "   'time',\n",
       "   'this',\n",
       "   'has',\n",
       "   'happened',\n",
       "   'and',\n",
       "   'I',\n",
       "   'am',\n",
       "   'so',\n",
       "   'sick',\n",
       "   'of',\n",
       "   'it'],\n",
       "  -1),\n",
       " (['I',\n",
       "   'may',\n",
       "   'be',\n",
       "   'ignorant',\n",
       "   'on',\n",
       "   'this',\n",
       "   'issue',\n",
       "   'but',\n",
       "   'should',\n",
       "   'we',\n",
       "   'celebrate',\n",
       "   'parental',\n",
       "   'leave',\n",
       "   'changes',\n",
       "   'Doesnt',\n",
       "   'the',\n",
       "   'gender',\n",
       "   'divide',\n",
       "   'suggest'],\n",
       "  -1),\n",
       " (['Thanks', 'to', 'I', 'just', 'may', 'be', 'switching', 'over', 'to'], -1),\n",
       " (['If',\n",
       "   'I',\n",
       "   'make',\n",
       "   'a',\n",
       "   'game',\n",
       "   'as',\n",
       "   'a',\n",
       "   'windows',\n",
       "   'Universal',\n",
       "   'App',\n",
       "   'Will',\n",
       "   'xboxone',\n",
       "   'owners',\n",
       "   'be',\n",
       "   'able',\n",
       "   'to',\n",
       "   'download',\n",
       "   'and',\n",
       "   'play',\n",
       "   'it',\n",
       "   'in',\n",
       "   'November'],\n",
       "  0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "# Separating our features (text) and our labels into two lists to smoothen our work\n",
    "X = df['tweet'].tolist()\n",
    "Y = df['label'].tolist()\n",
    "\n",
    "# Building our data list, that is a list of tuples, where each tuple is a pair of the tokenized text\n",
    "# and its corresponding label\n",
    "for x, y in zip(X, Y):\n",
    "    \n",
    "    data.append((nltk.word_tokenize(x), y))\n",
    "    \n",
    "# Printing the CPU time and the first 5 elements of our 'data' list\n",
    "#print('CPU Time:', time() - start_time)\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5462c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c679a7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dear', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('newOoffice', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('Mac', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('great', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('all', 'DT'),\n",
       " ('but', 'CC'),\n",
       " ('no', 'DT'),\n",
       " ('Lync', 'NNP'),\n",
       " ('update', 'NN'),\n",
       " ('Cmon', 'NNP')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e646ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dear', 'newooffice', 'mac', 'great', 'lync', 'update', 'cmon']\n"
     ]
    }
   ],
   "source": [
    "STOP_WORDS = stopwords.words('english')\n",
    "def lemmatize_sentence(tweet_tokens):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        # Eliminating the token if it is a link\n",
    "        \n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token.lower(), pos)\n",
    "\n",
    "        \n",
    "        # Eliminating the token if its length is less than 3, if it is a punctuation or if it is a stopword\n",
    "        if token not in string.punctuation and len(token) > 2 and token not in STOP_WORDS:\n",
    "            cleaned_tokens.append(token)\n",
    "            \n",
    "    return cleaned_tokens\n",
    "# Prevewing the remove_noise() output\n",
    "print(lemmatize_sentence(data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4275befd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Noise, CPU Time: 35.368741512298584\n",
      "Data Prepared for model, CPU Time: 0.02720952033996582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'dear': True,\n",
       "   'newooffice': True,\n",
       "   'mac': True,\n",
       "   'great': True,\n",
       "   'lync': True,\n",
       "   'update': True,\n",
       "   'cmon': True},\n",
       "  -1),\n",
       " ({'make': True,\n",
       "   'system': True,\n",
       "   'doesnt': True,\n",
       "   'eat': True,\n",
       "   'friggin': True,\n",
       "   'disc': True,\n",
       "   'time': True,\n",
       "   'happen': True,\n",
       "   'sick': True},\n",
       "  -1),\n",
       " ({'may': True,\n",
       "   'ignorant': True,\n",
       "   'issue': True,\n",
       "   'celebrate': True,\n",
       "   'parental': True,\n",
       "   'leave': True,\n",
       "   'change': True,\n",
       "   'doesnt': True,\n",
       "   'gender': True,\n",
       "   'divide': True,\n",
       "   'suggest': True},\n",
       "  -1),\n",
       " ({'thanks': True, 'may': True, 'switch': True}, -1),\n",
       " ({'make': True,\n",
       "   'game': True,\n",
       "   'window': True,\n",
       "   'universal': True,\n",
       "   'app': True,\n",
       "   'xboxone': True,\n",
       "   'owner': True,\n",
       "   'able': True,\n",
       "   'download': True,\n",
       "   'play': True,\n",
       "   'november': True},\n",
       "  0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "# As the Naive Bayesian classifier accepts inputs in a dict-like structure,\n",
    "# we have to define a function that transforms our data into the required input structure\n",
    "def list_to_dict(cleaned_tokens):\n",
    "    return dict([token, True] for token in cleaned_tokens)\n",
    "\n",
    "cleaned_tokens_list = []\n",
    "\n",
    "# Removing noise from all the data\n",
    "for tokens, label in data:\n",
    "    cleaned_tokens_list.append((lemmatize_sentence(tokens), label))\n",
    "\n",
    "print('Removed Noise, CPU Time:', time() - start_time)\n",
    "start_time = time()\n",
    "\n",
    "final_data = []\n",
    "\n",
    "# Transforming the data to fit the input structure of the Naive Bayesian classifier\n",
    "for tokens, label in cleaned_tokens_list:\n",
    "    final_data.append((list_to_dict(tokens), label))\n",
    "    \n",
    "print('Data Prepared for model, CPU Time:', time() - start_time)\n",
    "\n",
    "# Previewing our final (tokenized, cleaned and lemmatized) data list\n",
    "final_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7c259",
   "metadata": {},
   "source": [
    "## save tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3ad4ec87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luche\\AppData\\Local\\Temp/ipykernel_2568/1798639570.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokenized'][i] = cleaned_tokens_list[i][0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>embedding</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>negative</td>\n",
       "      <td>dear  the newOoffice for Mac is great and all ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[118309.0, 372306.0, 229153.0, 166369.0, 22830...</td>\n",
       "      <td>[dear, newooffice, mac, great, lync, update, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>how about you make a system that doesnt eat m...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[231458.0, 350362.0, 126852.0, 132701.0, 15409...</td>\n",
       "      <td>[make, system, doesnt, eat, friggin, disc, tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>I may be ignorant on this issue but should we ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[237383.0, 186885.0, 193637.0, 94875.0, 277466...</td>\n",
       "      <td>[may, ignorant, issue, celebrate, parental, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Thanks to  I just may be switching over to</td>\n",
       "      <td>-1</td>\n",
       "      <td>[357161.0, 237383.0, 349661.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[thanks, may, switch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a windows Universal App Wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[231458.0, 157049.0, 388091.0, 372227.0, 57667...</td>\n",
       "      <td>[make, game, window, universal, app, xboxone, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>ok good to know Punting at MetLife in Decembe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[164328.0, 209645.0, 295361.0, 242311.0, 11868...</td>\n",
       "      <td>[good, know, punt, metlife, december, task, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[141948.0, 333081.0, 59937.0, 242311.0, 55915....</td>\n",
       "      <td>[everyone, sit, around, metlife, annoying, did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[161068.0, 261597.0, 144744.0, 390139.0, 38289...</td>\n",
       "      <td>[giants, niner, fan, would, wan, sunday, night...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
       "      <td>1</td>\n",
       "      <td>[57178.0, 383068.0, 359356.0, 361707.0, 105227...</td>\n",
       "      <td>[anybody, want, ticket, tomorrow, colombia, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mendez told me hed drive me to MetLife on Sund...</td>\n",
       "      <td>0</td>\n",
       "      <td>[240866.0, 355345.0, 175719.0, 129440.0, 24231...</td>\n",
       "      <td>[mendez, tell, hed, drive, metlife, sunday, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5868 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "0     628949369883000832  negative   \n",
       "1     628976607420645377  negative   \n",
       "2     629023169169518592  negative   \n",
       "3     629179223232479232  negative   \n",
       "4     629186282179153920   neutral   \n",
       "...                  ...       ...   \n",
       "5863  639855845958885376  positive   \n",
       "5864  639979760735662080   neutral   \n",
       "5865  640196838260363269   neutral   \n",
       "5866  640975710354567168  positive   \n",
       "5867  641034340068143104   neutral   \n",
       "\n",
       "                                                  tweet  label  \\\n",
       "0     dear  the newOoffice for Mac is great and all ...     -1   \n",
       "1      how about you make a system that doesnt eat m...     -1   \n",
       "2     I may be ignorant on this issue but should we ...     -1   \n",
       "3          Thanks to  I just may be switching over to       -1   \n",
       "4     If I make a game as a windows Universal App Wi...      0   \n",
       "...                                                 ...    ...   \n",
       "5863   ok good to know Punting at MetLife in Decembe...      1   \n",
       "5864  everyone who sat around me at metlife was so a...      0   \n",
       "5865  what giants or niners fans would wanna go to t...      0   \n",
       "5866  Anybody want a ticket for tomorrow Colombia vs...      1   \n",
       "5867  Mendez told me hed drive me to MetLife on Sund...      0   \n",
       "\n",
       "                                              embedding  \\\n",
       "0     [118309.0, 372306.0, 229153.0, 166369.0, 22830...   \n",
       "1     [231458.0, 350362.0, 126852.0, 132701.0, 15409...   \n",
       "2     [237383.0, 186885.0, 193637.0, 94875.0, 277466...   \n",
       "3     [357161.0, 237383.0, 349661.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [231458.0, 157049.0, 388091.0, 372227.0, 57667...   \n",
       "...                                                 ...   \n",
       "5863  [164328.0, 209645.0, 295361.0, 242311.0, 11868...   \n",
       "5864  [141948.0, 333081.0, 59937.0, 242311.0, 55915....   \n",
       "5865  [161068.0, 261597.0, 144744.0, 390139.0, 38289...   \n",
       "5866  [57178.0, 383068.0, 359356.0, 361707.0, 105227...   \n",
       "5867  [240866.0, 355345.0, 175719.0, 129440.0, 24231...   \n",
       "\n",
       "                                              tokenized  \n",
       "0     [dear, newooffice, mac, great, lync, update, c...  \n",
       "1     [make, system, doesnt, eat, friggin, disc, tim...  \n",
       "2     [may, ignorant, issue, celebrate, parental, le...  \n",
       "3                                 [thanks, may, switch]  \n",
       "4     [make, game, window, universal, app, xboxone, ...  \n",
       "...                                                 ...  \n",
       "5863  [good, know, punt, metlife, december, task, ho...  \n",
       "5864  [everyone, sit, around, metlife, annoying, did...  \n",
       "5865  [giants, niner, fan, would, wan, sunday, night...  \n",
       "5866  [anybody, want, ticket, tomorrow, colombia, pe...  \n",
       "5867  [mendez, tell, hed, drive, metlife, sunday, re...  \n",
       "\n",
       "[5868 rows x 6 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized'] = ''\n",
    "for i in range(len(df)):\n",
    "    df['tokenized'][i] = cleaned_tokens_list[i][0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c799e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#pickle.dump(cleaned_tokens_list, open(\"./data.p\" , \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7fde7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb9b4561",
   "metadata": {},
   "source": [
    "## extra feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6309137f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       dear @Microsoft the newOoffice for Mac is grea...\n",
       "1       @Microsoft how about you make a system that do...\n",
       "2       I may be ignorant on this issue but... should ...\n",
       "3       Thanks to @microsoft, I just may be switching ...\n",
       "4       If I make a game as a #windows10 Universal App...\n",
       "                              ...                        \n",
       "5863    @Racalto_SK ok good to know. Punting at MetLif...\n",
       "5864    everyone who sat around me at metlife was so a...\n",
       "5865    what giants or niners fans would wanna go to t...\n",
       "5866    Anybody want a ticket for tomorrow Colombia vs...\n",
       "5867    Mendez told me he'd drive me to MetLife on Sun...\n",
       "Name: tweet, Length: 5868, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_back['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ee641e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurences(character, word_array):\n",
    "            counter = 0\n",
    "            for j, word in enumerate(word_array):\n",
    "                for char in word:\n",
    "                    if char == character:\n",
    "                        counter += 1\n",
    "            return counter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f79b3c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclamations = list(map(lambda txt: count_occurences(\"!\", txt),\n",
    "                                df_back['tweet']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a6f48507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>embedding</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>number of exclamations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>negative</td>\n",
       "      <td>dear  the newOoffice for Mac is great and all ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[118309.0, 372306.0, 229153.0, 166369.0, 22830...</td>\n",
       "      <td>[dear, newooffice, mac, great, lync, update, c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>how about you make a system that doesnt eat m...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[231458.0, 350362.0, 126852.0, 132701.0, 15409...</td>\n",
       "      <td>[make, system, doesnt, eat, friggin, disc, tim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>I may be ignorant on this issue but should we ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[237383.0, 186885.0, 193637.0, 94875.0, 277466...</td>\n",
       "      <td>[may, ignorant, issue, celebrate, parental, le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Thanks to  I just may be switching over to</td>\n",
       "      <td>-1</td>\n",
       "      <td>[357161.0, 237383.0, 349661.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[thanks, may, switch]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a windows Universal App Wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[231458.0, 157049.0, 388091.0, 372227.0, 57667...</td>\n",
       "      <td>[make, game, window, universal, app, xboxone, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>ok good to know Punting at MetLife in Decembe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[164328.0, 209645.0, 295361.0, 242311.0, 11868...</td>\n",
       "      <td>[good, know, punt, metlife, december, task, ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[141948.0, 333081.0, 59937.0, 242311.0, 55915....</td>\n",
       "      <td>[everyone, sit, around, metlife, annoying, did...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[161068.0, 261597.0, 144744.0, 390139.0, 38289...</td>\n",
       "      <td>[giants, niner, fan, would, wan, sunday, night...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
       "      <td>1</td>\n",
       "      <td>[57178.0, 383068.0, 359356.0, 361707.0, 105227...</td>\n",
       "      <td>[anybody, want, ticket, tomorrow, colombia, pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mendez told me hed drive me to MetLife on Sund...</td>\n",
       "      <td>0</td>\n",
       "      <td>[240866.0, 355345.0, 175719.0, 129440.0, 24231...</td>\n",
       "      <td>[mendez, tell, hed, drive, metlife, sunday, re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5868 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "0     628949369883000832  negative   \n",
       "1     628976607420645377  negative   \n",
       "2     629023169169518592  negative   \n",
       "3     629179223232479232  negative   \n",
       "4     629186282179153920   neutral   \n",
       "...                  ...       ...   \n",
       "5863  639855845958885376  positive   \n",
       "5864  639979760735662080   neutral   \n",
       "5865  640196838260363269   neutral   \n",
       "5866  640975710354567168  positive   \n",
       "5867  641034340068143104   neutral   \n",
       "\n",
       "                                                  tweet  label  \\\n",
       "0     dear  the newOoffice for Mac is great and all ...     -1   \n",
       "1      how about you make a system that doesnt eat m...     -1   \n",
       "2     I may be ignorant on this issue but should we ...     -1   \n",
       "3          Thanks to  I just may be switching over to       -1   \n",
       "4     If I make a game as a windows Universal App Wi...      0   \n",
       "...                                                 ...    ...   \n",
       "5863   ok good to know Punting at MetLife in Decembe...      1   \n",
       "5864  everyone who sat around me at metlife was so a...      0   \n",
       "5865  what giants or niners fans would wanna go to t...      0   \n",
       "5866  Anybody want a ticket for tomorrow Colombia vs...      1   \n",
       "5867  Mendez told me hed drive me to MetLife on Sund...      0   \n",
       "\n",
       "                                              embedding  \\\n",
       "0     [118309.0, 372306.0, 229153.0, 166369.0, 22830...   \n",
       "1     [231458.0, 350362.0, 126852.0, 132701.0, 15409...   \n",
       "2     [237383.0, 186885.0, 193637.0, 94875.0, 277466...   \n",
       "3     [357161.0, 237383.0, 349661.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [231458.0, 157049.0, 388091.0, 372227.0, 57667...   \n",
       "...                                                 ...   \n",
       "5863  [164328.0, 209645.0, 295361.0, 242311.0, 11868...   \n",
       "5864  [141948.0, 333081.0, 59937.0, 242311.0, 55915....   \n",
       "5865  [161068.0, 261597.0, 144744.0, 390139.0, 38289...   \n",
       "5866  [57178.0, 383068.0, 359356.0, 361707.0, 105227...   \n",
       "5867  [240866.0, 355345.0, 175719.0, 129440.0, 24231...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "0     [dear, newooffice, mac, great, lync, update, c...   \n",
       "1     [make, system, doesnt, eat, friggin, disc, tim...   \n",
       "2     [may, ignorant, issue, celebrate, parental, le...   \n",
       "3                                 [thanks, may, switch]   \n",
       "4     [make, game, window, universal, app, xboxone, ...   \n",
       "...                                                 ...   \n",
       "5863  [good, know, punt, metlife, december, task, ho...   \n",
       "5864  [everyone, sit, around, metlife, annoying, did...   \n",
       "5865  [giants, niner, fan, would, wan, sunday, night...   \n",
       "5866  [anybody, want, ticket, tomorrow, colombia, pe...   \n",
       "5867  [mendez, tell, hed, drive, metlife, sunday, re...   \n",
       "\n",
       "      number of exclamations  \n",
       "0                          0  \n",
       "1                          1  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "...                      ...  \n",
       "5863                       0  \n",
       "5864                       0  \n",
       "5865                       0  \n",
       "5866                       0  \n",
       "5867                       0  \n",
       "\n",
       "[5868 rows x 7 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['number of exclamations'] = exclamations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec67bf",
   "metadata": {},
   "source": [
    "## load saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e7371a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './data.p'\n",
    "\n",
    "def load_data(root):\n",
    "    \"\"\"Load data from saved files generated in 'dataset_preprocess.py' \"\"\"\n",
    "    data = pickle.load(open(root, \"rb\"))\n",
    "    return data\n",
    "\n",
    "cleaned_tokens_list = load_data(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fae8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f66ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495361c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the 50-dimensional GloVe embeddings\n",
    "# This method will return three dictionaries:\n",
    "# * word_to_index: a dictionary mapping from words to their indices in the vocabulary\n",
    "# * index_to_word: dictionary mapping from indices to their corresponding words in the vocabulary\n",
    "# * word_to_vec_map: dictionary mapping words to their GloVe vector representation\n",
    "# Note that there are 400,001 words, with the valid indices ranging from 0 to 400,000\n",
    "glove_file = 'glove.6B.100d.txt'\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(glove_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab59a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    dot = np.dot(u, v)\n",
    "    norm_u = np.sqrt(np.sum(u**2))\n",
    "    norm_v = np.sqrt(np.sum(v**2))\n",
    "    cosine_similarity = dot / (norm_u * norm_v)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab9ebb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Noise, CPU Time: 0.0009965896606445312\n",
      "max_len: 536\n",
      "Data Prepared for model, CPU Time: 0.04639863967895508\n",
      "[[118309. 372306. 229153. ...      0.      0.      0.]\n",
      " [231458. 350362. 126852. ...      0.      0.      0.]\n",
      " [237383. 186885. 193637. ...      0.      0.      0.]\n",
      " ...\n",
      " [227517. 169725. 174666. ...      0.      0.      0.]\n",
      " [278611. 366910. 188929. ...      0.      0.      0.]\n",
      " [237383. 329448. 248238. ...      0.      0.      0.]]\n",
      "[-1. -1. -1. -1.  0.  1. -1. -1.  1. -1.  1. -1. -1.  0.  1.  0.  0. -1.\n",
      " -1.  1.  1. -1.  1. -1.  1.  1.  0. -1. -1. -1.  0.  0. -1. -1. -1. -1.\n",
      " -1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  0. -1.  1.  1.  1. -1.\n",
      " -1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1.  0.  1.  0. -1. -1.  1.  0.\n",
      "  0.  1.  1.  1.  0.  1. -1.  1.  0. -1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      " -1.  1. -1.  1.  1.  0.  1. -1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "unks = []\n",
    "UNKS = []\n",
    "\n",
    "# This function will act as a \"last resort\" in order to try and find the word\n",
    "# in the words embedding layer. It will basically eliminate contiguously occuring\n",
    "# instances of a similar character\n",
    "def cleared(word):\n",
    "    res = \"\"\n",
    "    prev = None\n",
    "    for char in word:\n",
    "        if char == prev: continue\n",
    "        prev = char\n",
    "        res += char\n",
    "    return res\n",
    "\n",
    "\n",
    "def sentence_to_indices(sentence_words, word_to_index, max_len, i):\n",
    "    global X, Y\n",
    "    sentence_indices = []\n",
    "    for j, w in enumerate(sentence_words):\n",
    "        try:\n",
    "            index = word_to_index[w]\n",
    "        except:\n",
    "            UNKS.append(w)\n",
    "            w = cleared(w)\n",
    "            try:\n",
    "                index = word_to_index[w]\n",
    "            except:\n",
    "                index = word_to_index['unk']\n",
    "                unks.append(w)\n",
    "        X[i, j] = index\n",
    "\n",
    "\n",
    "# Here we will utilize the already computed 'cleaned_tokens_list' variable\n",
    "   \n",
    "print('Removed Noise, CPU Time:', time() - start_time)\n",
    "start_time = time()\n",
    "\n",
    "list_len = [len(i) for i, j in cleaned_tokens_list]\n",
    "max_len = max(list_len)\n",
    "print('max_len:', max_len)\n",
    "\n",
    "X = np.zeros((len(cleaned_tokens_list), max_len))\n",
    "Y = np.zeros((len(cleaned_tokens_list), ))\n",
    "\n",
    "for i, tk_lb in enumerate(cleaned_tokens_list):\n",
    "    tokens, label = tk_lb\n",
    "    sentence_to_indices(tokens, word_to_index, max_len, i)\n",
    "    Y[i] = label\n",
    "    \n",
    "print('Data Prepared for model, CPU Time:', time() - start_time)\n",
    "\n",
    "\n",
    "print(X[:100])\n",
    "print(Y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "20c53867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118309., 372306., 229153., ...,      0.,      0.,      0.],\n",
       "       [231458., 350362., 126852., ...,      0.,      0.,      0.],\n",
       "       [237383., 186885., 193637., ...,      0.,      0.,      0.],\n",
       "       [357161., 237383., 349661., ...,      0.,      0.,      0.],\n",
       "       [231458., 157049., 388091., ...,      0.,      0.,      0.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb4f23e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118309., 372306., 229153., ...,      0.,      0.,      0.],\n",
       "       [231458., 350362., 126852., ...,      0.,      0.,      0.],\n",
       "       [237383., 186885., 193637., ...,      0.,      0.,      0.],\n",
       "       ...,\n",
       "       [161068., 261597., 144744., ...,      0.,      0.,      0.],\n",
       "       [ 57178., 383068., 359356., ...,      0.,      0.,      0.],\n",
       "       [240866., 355345., 175719., ...,      0.,      0.,      0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4eb643a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>negative</td>\n",
       "      <td>dear  the newOoffice for Mac is great and all ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>how about you make a system that doesnt eat m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>I may be ignorant on this issue but should we ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Thanks to  I just may be switching over to</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a windows Universal App Wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>ok good to know Punting at MetLife in Decembe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mendez told me hed drive me to MetLife on Sund...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5868 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "0     628949369883000832  negative   \n",
       "1     628976607420645377  negative   \n",
       "2     629023169169518592  negative   \n",
       "3     629179223232479232  negative   \n",
       "4     629186282179153920   neutral   \n",
       "...                  ...       ...   \n",
       "5863  639855845958885376  positive   \n",
       "5864  639979760735662080   neutral   \n",
       "5865  640196838260363269   neutral   \n",
       "5866  640975710354567168  positive   \n",
       "5867  641034340068143104   neutral   \n",
       "\n",
       "                                                  tweet  label  \n",
       "0     dear  the newOoffice for Mac is great and all ...     -1  \n",
       "1      how about you make a system that doesnt eat m...     -1  \n",
       "2     I may be ignorant on this issue but should we ...     -1  \n",
       "3          Thanks to  I just may be switching over to       -1  \n",
       "4     If I make a game as a windows Universal App Wi...      0  \n",
       "...                                                 ...    ...  \n",
       "5863   ok good to know Punting at MetLife in Decembe...      1  \n",
       "5864  everyone who sat around me at metlife was so a...      0  \n",
       "5865  what giants or niners fans would wanna go to t...      0  \n",
       "5866  Anybody want a ticket for tomorrow Colombia vs...      1  \n",
       "5867  Mendez told me hed drive me to MetLife on Sund...      0  \n",
       "\n",
       "[5868 rows x 4 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d6096da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luche\\AppData\\Local\\Temp/ipykernel_2568/186184679.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['embedding'][i] = X[i]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>negative</td>\n",
       "      <td>dear  the newOoffice for Mac is great and all ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[118309.0, 372306.0, 229153.0, 166369.0, 22830...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>how about you make a system that doesnt eat m...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[231458.0, 350362.0, 126852.0, 132701.0, 15409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>I may be ignorant on this issue but should we ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[237383.0, 186885.0, 193637.0, 94875.0, 277466...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Thanks to  I just may be switching over to</td>\n",
       "      <td>-1</td>\n",
       "      <td>[357161.0, 237383.0, 349661.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a windows Universal App Wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[231458.0, 157049.0, 388091.0, 372227.0, 57667...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>ok good to know Punting at MetLife in Decembe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[164328.0, 209645.0, 295361.0, 242311.0, 11868...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[141948.0, 333081.0, 59937.0, 242311.0, 55915....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[161068.0, 261597.0, 144744.0, 390139.0, 38289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
       "      <td>1</td>\n",
       "      <td>[57178.0, 383068.0, 359356.0, 361707.0, 105227...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mendez told me hed drive me to MetLife on Sund...</td>\n",
       "      <td>0</td>\n",
       "      <td>[240866.0, 355345.0, 175719.0, 129440.0, 24231...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5868 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "0     628949369883000832  negative   \n",
       "1     628976607420645377  negative   \n",
       "2     629023169169518592  negative   \n",
       "3     629179223232479232  negative   \n",
       "4     629186282179153920   neutral   \n",
       "...                  ...       ...   \n",
       "5863  639855845958885376  positive   \n",
       "5864  639979760735662080   neutral   \n",
       "5865  640196838260363269   neutral   \n",
       "5866  640975710354567168  positive   \n",
       "5867  641034340068143104   neutral   \n",
       "\n",
       "                                                  tweet  label  \\\n",
       "0     dear  the newOoffice for Mac is great and all ...     -1   \n",
       "1      how about you make a system that doesnt eat m...     -1   \n",
       "2     I may be ignorant on this issue but should we ...     -1   \n",
       "3          Thanks to  I just may be switching over to       -1   \n",
       "4     If I make a game as a windows Universal App Wi...      0   \n",
       "...                                                 ...    ...   \n",
       "5863   ok good to know Punting at MetLife in Decembe...      1   \n",
       "5864  everyone who sat around me at metlife was so a...      0   \n",
       "5865  what giants or niners fans would wanna go to t...      0   \n",
       "5866  Anybody want a ticket for tomorrow Colombia vs...      1   \n",
       "5867  Mendez told me hed drive me to MetLife on Sund...      0   \n",
       "\n",
       "                                              embedding  \n",
       "0     [118309.0, 372306.0, 229153.0, 166369.0, 22830...  \n",
       "1     [231458.0, 350362.0, 126852.0, 132701.0, 15409...  \n",
       "2     [237383.0, 186885.0, 193637.0, 94875.0, 277466...  \n",
       "3     [357161.0, 237383.0, 349661.0, 0.0, 0.0, 0.0, ...  \n",
       "4     [231458.0, 157049.0, 388091.0, 372227.0, 57667...  \n",
       "...                                                 ...  \n",
       "5863  [164328.0, 209645.0, 295361.0, 242311.0, 11868...  \n",
       "5864  [141948.0, 333081.0, 59937.0, 242311.0, 55915....  \n",
       "5865  [161068.0, 261597.0, 144744.0, 390139.0, 38289...  \n",
       "5866  [57178.0, 383068.0, 359356.0, 361707.0, 105227...  \n",
       "5867  [240866.0, 355345.0, 175719.0, 129440.0, 24231...  \n",
       "\n",
       "[5868 rows x 5 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['embedding'] = ''\n",
    "for i in range(len(df)):\n",
    "    df['embedding'][i] = X[i]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6eff86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf01a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional,GlobalMaxPool1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9729792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_seed = 22\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b54b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "Y1 = to_categorical(Y,3)\n",
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3205e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index, max_len):\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"unk\"].shape[0] #50\n",
    "    \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "        \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False, input_shape=(max_len,))\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0497e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 536, 100)          40000100  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 536, 128)          84480     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 536, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 40,364,391\n",
      "Trainable params: 364,291\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining a sequencial model composed of firstly the embedding layer, than a pair of Bidirectional LSTMs,\n",
    "# that finally feed into a sigmoid layer that generates our desired output betwene 0 and 1.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(pretrained_embedding_layer(word_to_vec_map, word_to_index, max_len))\n",
    "model.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
    "\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
    "\n",
    "model.add(Dropout(rate=0.4))\n",
    "#model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(units=64,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "model.add(Dense(units=3,kernel_initializer=\"uniform\",activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd11dbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 536, 100)          40000100  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 536, 512)          731136    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 40,797,287\n",
      "Trainable params: 797,187\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining a sequencial model composed of firstly the embedding layer, than a pair of Bidirectional LSTMs,\n",
    "# that finally feed into a sigmoid layer that generates our desired output betwene 0 and 1.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(pretrained_embedding_layer(word_to_vec_map, word_to_index, max_len))\n",
    "model.add(Bidirectional(LSTM(256,return_sequences=True), merge_mode = 'concat'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense((3), activation=\"softmax\"))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "087d9c91",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21108/2144145163.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrainx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'embedding'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'number of exclamations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "trainx = df.filter(['embedding','number of exclamations']).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e47327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80b5a655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['number of exclamations'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1c82628",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =tf.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='CategoricalCrossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60775cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e570c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(trainx, Y1, test_size=0.2, random_state=0, stratify=Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99797886",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='./data/weights.best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath= filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "earlyStop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=20, mode='min', verbose=1, restore_best_weights = True)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d526500",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21108/876271992.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs = 50, batch_size = 128, shuffle=True,callbacks=callbacks_list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1132\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1135\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m                **kwargs):\n\u001b[0;32m    229\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    232\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m-> 1430\u001b[1;33m   return convert_to_tensor_v2(\n\u001b[0m\u001b[0;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   \u001b[1;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m   return convert_to_tensor(\n\u001b[0m\u001b[0;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs = 50, batch_size = 128, shuffle=True)\n",
    "#model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs = 50, batch_size = 128, shuffle=True,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d577281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./lstm-4-7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(history):\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label = 'Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label = 'Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label = 'Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecfd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss(model.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
